{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Innovate Data Academy\n",
    "[Krisolis](http://www.krisolis.ie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop 1 Simple Predictive Models In Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General data handling\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 1000) \n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "import numpy as np\n",
    "\n",
    "# Drawing plots\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# \n",
    "# Machine learning with scikit-learn\n",
    "import sklearn\n",
    "import sklearn.impute\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Credit scoring is one of the most established uses of machine learning and predictive modeling in finance. By recognizing the patterns that precede borrowers running into financial distress banks can take action to avoid negative impacts of this. In this workshop you will use a dataset of past borrowers to build a model that predicts the likelihood that a borrower will experience financial distress in the next two years.\n",
    "\n",
    "The descriptive features available to describe borrowers are:\n",
    "\n",
    "- **Age**:\tThe age of borrower in years.\n",
    "- **CustomerLifeTime**: How long the borrower has been a customer of the bank. \n",
    "- **MonthlyIncome**: The borrower's Monthly gross income.\n",
    "- **NumberOfDependents**: Number of dependents (e.g. spouse or children) in the borrower's family (excluding themselves)\n",
    "- **NumberOfTime30_59DaysLateNotWorse**: Number of times borrower has previously been 30-59 days past due, but no worse, in the last 2 years.\n",
    "- **NumberOfTime60_89DaysLateNotWorse**: Number of times borrower has previously been 60-89 days past due, but no worse, in the last 2 years.\n",
    "- **NumberOfTimes90DaysLate**: The number of times the borrower has previously been 90 days or more past due.\n",
    "- **DebtRatio**: Monthly debt payments plus other living expenses paid by the borrower, divided by their monthly gross income.\n",
    "- **NumberOfOpenCreditLinesAndLoans**: The number of existing loans (e.g. car loans or mortgages) and other lines of credit (e.g. credit cards) that the borrower currently holds. \n",
    "- **NumberRealEstateLoansOrLines**: Number of mortgage and other real estate loans held by the borrower.\n",
    "- **UtilizationOfUnsecuredLinesTotal**: Total balance the borrower owes on credit cards and other short term loans, divided by the sum of their credit limits.\n",
    "\n",
    "The target feature to predict is: \n",
    "\n",
    "- **SeriousDlqin2yrs**:\tThe borrower experienced 90 days past due delinquency or worse in the following 2 years (0 = No, 1 = Yes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Load the dataset from the file **credit_scoring_bal.csv** into a Python data frame called `dataset`. View its shape, the column headings, and the first and last few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature_name = 'SeriousDlqin2yrs'\n",
    "\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Extract the descriptive features into a DataFrame named `X` and the target feature into a Series named `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the shape, column headings, and the first and last few rows for `X` and `y` (note `y` will not have column names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 \n",
    "Divide the available dataset into a training partition (70%) - `X_train` and `y_train` - and a validation partition (30%)  - `X_valid` and `y_valid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a decision tree classifier object using '*entropy*' as the splitting `criterion` and all other default hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf = # Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the decision tree classifier using its `fit` function with the data in `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a representation of the decision tree - what feature was chosen to be examined at the root node? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.tree.export_text(model_clf, \n",
    "                               feature_names = X_train.columns.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the decision tree - **WATCH OUT!** this tree is most likely very big and will take a long time to draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(10,10))\n",
    "#_ = sklearn.tree.plot_tree(model_clf, \n",
    "#                           feature_names = X_train.columns,\n",
    "#                           class_names = model_clf.classes_,\n",
    "#                           filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Make predictions for each of the instances in the **training dataset** and assess the performance of the trained decision tree based on these predictions using **accuracy**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for each of the instances in the **validation dataset** and assess the performance of the trained decision tree based on these predictions using **accuracy**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What might explain the difference between these performance scores? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "Train a more effective decision tree by setting the `min_samples_leaf` hyper parameter to 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_clf = # Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a representation of the decision tree - what feature was chosen to be examined at the root node? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.tree.export_text(model_clf, \n",
    "                               feature_names = X_train.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "_ = sklearn.tree.plot_tree(model_clf, \n",
    "                           feature_names = X_train.columns,\n",
    "                           class_names = model_clf.classes_,\n",
    "                           filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the previous evaluation on the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "The file **credit_scoring_query.csv** contains a set of query instances for which predictions need to be made. Load this file into a DataFrame named `X_query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model trained to make a set of predictions for the instances in `X_query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = # Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the predictions made using the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'prediction' : y_pred})\n",
    "print(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "329.688px",
    "left": "41px",
    "top": "67.125px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
