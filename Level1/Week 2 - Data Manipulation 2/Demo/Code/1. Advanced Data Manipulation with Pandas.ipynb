{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECB Data Academy - Evolve Programme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Krisolis](http://www.theanalyticsstore.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Data Manipulation With Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores more advanced data manipulation operations in pandas that allow us to create sophisticated datasets from multiple sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a dataset containing details about different world nations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_ind = pd.read_csv(\"..//Data//world_indicators_data_ext.csv\", index_col = 0)\n",
    "print(country_ind.shape)\n",
    "display(country_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file *first_languages.csv*  contains a list of the first languages spoken in the countries in the list of indciators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_langs = pd.read_csv(\"..//Data//first_languages.csv\")\n",
    "print(first_langs.shape)\n",
    "display(first_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add these columns directly onto the data frame - **this assumes the data is in the same order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_ind_2 = pd.concat([country_ind, first_langs], \n",
    "                        axis = 0)\n",
    "display(country_ind_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new rows to a DataFrame is easy using the **append** method. first load up some new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extra_rows = pd.read_csv(\"..//Data//world_indicators_data_short.csv\", index_col = 0)\n",
    "display(extra_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the rows from the new dataframe to the existing one - notice how it handles missing and extra columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([country_ind, extra_rows], \n",
    "          axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also *merge* together DataFrames in SQL style join operations using the **merge** method. First load some extra data - in this case the populations of countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "populations = pd.read_csv(\"..//Data//populations.csv\",\n",
    "                         index_col=0)\n",
    "display(populations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pefrom a merge of country indciators and populations using country names as the common key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_ind_with_pop = pd.merge(country_ind, \n",
    "                                populations, \n",
    "                                on=\"Country\")\n",
    "display(country_ind_with_pop)\n",
    "print(country_ind.shape)\n",
    "print(populations.shape)\n",
    "print(country_ind_with_pop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **how** parameter to the merge method determines the type of join that is performed - the options are 'left', 'right', 'outer', 'inner' (the default is 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_ind_with_pop = pd.merge(country_ind, \n",
    "                                populations, \n",
    "                                on=\"Country\", \n",
    "                                how = 'left')\n",
    "display(country_ind_with_pop)\n",
    "print(country_ind.shape)\n",
    "print(populations.shape)\n",
    "print(country_ind_with_pop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "country_ind_with_pop = pd.merge(country_ind, \n",
    "                                populations, \n",
    "                                on=\"Country\", \n",
    "                                how = 'right')\n",
    "display(country_ind_with_pop)\n",
    "print(country_ind.shape)\n",
    "print(populations.shape)\n",
    "print(country_ind_with_pop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "country_ind_with_pop = pd.merge(country_ind, \n",
    "                                populations, \n",
    "                                on=\"Country\", \n",
    "                                how = 'outer')\n",
    "display(country_ind_with_pop)\n",
    "print(country_ind.shape)\n",
    "print(populations.shape)\n",
    "print(country_ind_with_pop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now you try ...\n",
    "\n",
    "Load the dataset stored in the file **TriathloneData.csv**. The variables in this dataset are as follows:\n",
    "\n",
    "* **Place:** The place in which the athlete finished the race (missing for non-finishers)\n",
    "* **Number:** The athlete's race bib number\n",
    "* **Wave:** The wave with which the athlete started (one of 1, 2, or 3)\n",
    "* **Age_Cat:** The athlete's age category (one of 16-19, 20-29, 30-39, 40-49, or 50+)\n",
    "* **Gender:** The gender that the athlete declared (one of 'M' or 'F')\n",
    "* **TI_Number:** Some athlete's are members of the Traithlon Ireland association and if so declare their membership number\t\n",
    "* **Swim:** The time taken for the swimming leg of the event (in seconds)\n",
    "* **T1:** The time taken for the first transition of the event (in seconds)\n",
    "* **Cycle:** The time taken for the cycling leg of the event (in seconds)\n",
    "* **T2:** The time taken for the swimming leg of the event (in seconds)\n",
    "* **Run:** The time taken for the running leg of the event (in seconds)\n",
    "* **Finish:** The time taken for the total event ( in seconds)\n",
    "    \n",
    "Also the dataset stored in the file **provinces.csv**. This dataset stores the Irish proviince to which each athlete belongs. The variables in this dataset are as follows:\n",
    "\n",
    "* **Number:** The athlete's race bib number\n",
    "* **Province:** The Irish province in which the athlete lives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the province data to the main race dataset using the bib number as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the new joined dataseet calcualte the average finishing time fro each province. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are a categoricial variables in a dataset we can use them to define groups. Once groups are defined it is possible to perform analysis based on these groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define groups within a dataframe we use the **groupby** function, passing it the name of the column we would like to group by. Using the grouped data then we can then perform grouped analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_ind_grp = country_ind.groupby(['Region'])\n",
    "country_ind_grp.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using groups we can also perform **data aggregation** jobs - rolling up muptiple rows of data into a single row that aggregates them. To do this we use the **agg** function in conection with grouped data. For example to create a dataset containing the mean life expectancy of each continent we could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_ind_grp['Life Exp.'].agg([np.mean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add multiple measurs to this aggregation - for example including max and min as well as mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_ind_grp['Life Exp.'].agg([np.mean, np.min, np.max, len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this for multiple columns from the original dataset to be even more expressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_ind_grp[['Life Exp.', 'Infant Mort.']].agg([np.mean, np.min, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can pass a dictionary showing different funcctions to use for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_ind_grp.agg({\"Region\": len, \"Life Exp.\":[np.mean], \"Infant Mort.\":[min], \"School Years\": [max]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now you try ...\n",
    "\n",
    "Using the Triathlone dataset create an aggregated version of the data that stores the min, median, and max cycling, swimming and running times for each province. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Data - Optional Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different data analytics tools and techniques work with data in different formats, or shapes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplest reshaping we go can is a **transpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(country_ind.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = country_ind.transpose()\n",
    "display(trans.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert from *short, fat* data to *long, skinny* data using a **melt** operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_fat_olympic_data = pd.read_csv(\"..//Data//Olympic_Medal_Count.csv\")\n",
    "short_fat_olympic_data = short_fat_olympic_data.loc[0:11]\n",
    "short_fat_olympic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Melt the data\n",
    "long_skinny_olympic_data = \\\n",
    "pd.melt(short_fat_olympic_data, id_vars=[\"Year\"], \\\n",
    "        var_name = \"Medal\", \\\n",
    "        value_name = \"Count\") \n",
    "\n",
    "\n",
    "display(long_skinny_olympic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert from *long, skinny* data to *short, fat* data using a **cast** (or pivot) operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data\n",
    "quarterly_liabilities_data=\"..//Data//quarterly_liabilities.csv\"\n",
    "long_skinny_liabilities = pd.read_csv(quarterly_liabilities_data)\n",
    "long_skinny_liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cast to short fat data\n",
    "short_fat_liabilities  = \\\n",
    "long_skinny_liabilities.pivot(index = \"Account\", \\\n",
    "                              columns= \"Quarter\",  values=\"Liability\")\n",
    "\n",
    "display(short_fat_liabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting occurences of different levels is a really common application of casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data\n",
    "form_submission_data=\"..//Data//form_submission.csv\"\n",
    "long_skinny_form_sub = pd.read_csv(form_submission_data)\n",
    "\n",
    "# Cast to one row per subject\n",
    "#one_row_per_cust_form_sub = long_skinny_form_sub.pivot(index = \"Cust_ID\", columns = \"Type\")\n",
    "\n",
    "one_row_per_cust_form_sub = \\\n",
    "pd.pivot_table(long_skinny_form_sub, \\\n",
    "               index = \"Cust_ID\", \\\n",
    "               columns = \"Type\", aggfunc=len, fill_value = 0)\n",
    "display(one_row_per_cust_form_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
